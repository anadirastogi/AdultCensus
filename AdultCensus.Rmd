---
title: "Adult Census Project"
author: "Group 4 (Adi, Pam, Jennifer, Jason)"
date: "April 19, 2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

##Data preprocessing
##Clear workspace
```{r}
rm(list = ls())
```

##Libraries and packages
```{r}
install.packages("e1071")
library(e1071)
library(tidyverse)
library(ggplot2)
install.packages("pROC")
library(pROC)
```

##Read file and view data

We read the file into R and look at the data to get a sense of what we are working with.
```{r}
mydata<-read.csv(file = "adult.csv")
head(mydata)
```

##Save dataset in tidy way 
```{r}
mydata<-as_tibble(mydata)
View(mydata)
```

##Check for null values and count the number of null values

Since there are a number of records in our data that contain "?" we first need to let R know that these are missing values
```{r}
## null values appear as a questionmark in the data
## set ? = NA
mydata$workclass[mydata$workclass == "?"] <- NA
mydata$occupation[mydata$occupation == "?"] <- NA
mydata$native.country[mydata$native.country == "?"] <- NA

## Count number of missing values
sum(is.na(mydata))

## we have 4262 missing values in our dataset
```

## analyze missing values
```{r}
## want to look at missing values to better understand the source/cause of missing data
## quick visual inspection shows us that wherever occupation is NA, workclass is also NA
mydata%>%
  filter(is.na(occupation))%>%
  arrange(education, marital.status)

## upon a quick visual inspection, there does not seem to be an obvious relationship between the records with missing information, therefore we will seek to simply remove the missing values
```

## Remove missing values
```{r}
mydata2<-na.omit(mydata)

head(mydata2)
```

## Data Visualization

# a bar chart showing relationship between income and education
```{r}
mydata2%>%
ggplot(aes(x=education.num, y=1, fill=income))+ 
  geom_bar(stat = "identity", position = "stack")

```
## plotting relationships of the other attribues with income (target variable)
```{r}

## Numeric Variables

##ecucation.num vs income
mydata2%>%
  ggplot(aes(x=education.num,fill=income))+geom_histogram(binwidth=1,position="stack")+
  facet_wrap(~income)

##age vs income
mydata2%>%
  ggplot(aes(x=age,fill=income))+geom_histogram(binwidth=15)+
  facet_wrap(~income)

mydata2%>%
  ggplot(aes(x=age,fill=income))+geom_histogram(binwidth=1, colour="black", position="stack")

##capital.loss vs income
mydata2%>%
  ggplot(aes(x=capital.loss,fill=income))+geom_histogram(binwidth=500)+
  facet_wrap(~income)

##capital.gain vs income
mydata2%>%
  ggplot(aes(x=capital.gain,fill=income))+geom_histogram(binwidth=20000)+
  facet_wrap(~income)

## hours worked vs income
mydata2%>%
  ggplot(aes(x=hours.per.week,fill=income))+geom_histogram(binwidth=5, colour="black", position="stack")

```
```{r}
## Categorical variables

## occupation vs income
mydata2%>%
  ggplot(aes(x=occupation,fill=income))+geom_bar(size=5)+coord_flip()

## education vs income
mydata2%>%
  ggplot(aes(x=education,fill=income))+geom_bar(size=5)+coord_flip()
```

## Looking at target variable
```{r}
## check how many records have income >50k and how many do not
table(mydata2$income)
## we see that most of the records indicate income of <=50k, only ~25% have >50k

mydata2%>%
  ggplot(aes(x=income, fill=education))+geom_bar(size=5)

mydata2%>%
  ggplot(aes(x=income, fill=sex))+geom_bar(size=5)
## men are a bigger % of the high earners than females

```
###### Split data into training and testing set
```{r}
set.seed(1)
idx <- sample(2,nrow(mydata2),replace=TRUE,prob=c(.8,.2)) # "idx" is an index, which tells us which observations were assigned to the training (idx=1) and validation (idx=2) samples 
table(idx) # confirm 80/20 split
```

##### SVM
```{r}

reg<- glm(income~age+workclass+education+education.num+marital.status+occupation+relationship+race+sex+capital.gain+capital.loss+hours.per.week+native.country, family="binomial", data=mydata2[idx==1,])
summary(reg)

```
```{r}
plot(mydata2)
```

## set up initial model
```{r}


model_svm<-svm(formula=income~age+workclass+marital.status+occupation+sex+capital.gain+capital.loss+hours.per.week, ## these two are the most linearly seperable
               #+marital.status+occupation+relationship+sex+hours.per.week, # model formula 
               data=mydata2[idx==1,],                   # dataset
               kernel="linear", # linear decision boundary
               cost=1,        # there are paremeters that are used to tune the model 
               scale=FALSE)

model_svm
```
## plot model results
```{r}


plot(model_svm,mydata2[idx==1,],age~capital.gain~workclass~marital.status~occupation~sex~capital.loss~hours.per.week)
     
```
```{r}
head(model_svm$index)  #the support vectors of the model
```
## Decision values are the distance between the observation and the decision boundary. The positive fitted value indicate one class, and negative value indicates the other class. 
```{r}
dv<-data.frame(model_svm$decision.values) ## need dataframe to plot using ggplot
ggplot(dv, aes(x=model_svm$decision.values)) + 
  geom_histogram(binwidth=1000, colour="black",fill="white")
```
```{r}
head(model_svm$fitted)  # predicted (fitted) class

## Predict values using svm model
predicted_svm<-predict(model_svm,mydata2,decision.values = TRUE) 

head(attr(predicted_svm, "decision.values"))
```

```{r}
mydata2$svm_pred_class <- predict(model_svm, mydata2) 
mydata2$svm_dv<-attr(predicted_svm, "decision.values")
```


## Tuning
## SVM
We can tune SVM models using `tune` function. Set a range of search values for the parameter. It builds an SVM model for each possible combination of parameter values and evaluate accuracy. It will return the parameter combination that yields the best accuracy. 
```{r}
svm_tune <- tune(svm,                            # find a best set of parameters for the svm model           
                 income~age+workclass+marital.status+occupation+sex+capital.gain+capital.loss+hours.per.week,         
                 data = mydata2[idx==1,],
                 kernel="linear", 
                 ranges = list(cost = 10^(-5:0))) # specifying the ranges of parameters  
                                                  # in the penalty function to be examined
                                                  # you may wish to increase the search space like 
                                                  

print(svm_tune)                              # best parameters for the model
best_svm_mod <- svm_tune$best.model
test$svm_pred_class <- predict(best_svm_mod, test) # save the predicted class by the svm model
test$svm_dv<-as.numeric(attr(predict(best_svm_mod, test, decision.values = TRUE),"decision.values"))
```


## Validating
```{r}

```

## Performance Visualization with ROC

```{r}

ct_roc<-roc(test$default,test$ct_pred_prob,auc=TRUE)
plot(ct_roc,print.auc=TRUE,col="blue")

rf_roc<-roc(test$default,test$rf_pred_prob,auc=TRUE)
plot(rf_roc,print.auc=TRUE,print.auc.y=.4,col="green", add=TRUE)


logit_roc<-roc(test$default,test$logit_pred_prob,auc=TRUE)
plot(logit_roc,print.auc=TRUE,print.auc.y=.3, col="red",add=TRUE)

svm_roc<-roc(test$default,test$svm_dv,auc=TRUE)
plot(svm_roc,print.auc=TRUE,print.auc.y=.2, col="black",add=TRUE)

