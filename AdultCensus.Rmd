---
title: "Adult Census Project"
author: "Group 4 (Adi, Pam, Jennifer, Jason)"
date: "April 19, 2019"
output: word_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdownuuuy

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

##Clear workspace
```{r}
rm(list = ls())
```

##Libraries and packages
```{r}

library(tidyverse)
```

##Read file and view data

We read the file into R and look at the data to get a sense of what we are working with.
```{r}
mydata<-read.csv(file = "adult.csv")
head(mydata)
```

##Save dataset in tidy way 
```{r}
mydata<-as_tibble(mydata)
```

##Check for null values and count the number of null values

Since there are a number of records in our data that contain "?" we first need to let R know that these are missing values
```{r}
## set ? = NA
mydata$workclass[mydata$workclass == "?"] <- NA
mydata$occupation[mydata$occupation == "?"] <- NA
mydata$native.country[mydata$native.country == "?"] <- NA

## Count number of missing values
 
sum(is.na(mydata))

## we have 4262 missing values in our dataset
```
## Remove missing values
```{r}
clean<-na.omit(mydata)
```
```{r}
View(clean)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

# a plot showing relationship between income and education and hours per week
```{r}
mydata%>%
ggplot(aes(x=education.num, y=1, fill=income))+ 
  geom_bar(stat = "identity", position = "stack")

```

```{r}
mydata%>%
  ggplot(aes(x=education.num,fill=income))+geom_histogram(binwidth=1,position="stack")+
  facet_wrap(~income)

mydata%>%
  ggplot(aes(x=,fill=income))+geom_histogram(binwidth=15)+
  facet_wrap(~income)

mydata%>%
  ggplot(aes(x=capital.loss,fill=income))+geom_histogram(binwidth=500)+
  facet_wrap(~income)

mydata%>%
  ggplot(aes(x=capital.gain,fill=income))+geom_histogram(binwidth=20000)+
  facet_wrap(~income)

```
#
```{r}
set.seed(1)   # set a random seed 
index <- sample(30162,6000) # random selection of indices. 
test <- clean[index,]       # save 20% as a test dataset
training <-clean[-index,]   # save the rest as a training set
```

#Tree-based classification model
```{r}
library(rpart)
library(rpart.plot)
training_model<-rpart(income~.,           # model formula
                data=training,                     # dataset
                method="class",                   # "class" indicates a classification tree model 
                control=rpart.control(cp=0.03))   # tree control parameters. 
rpart.plot(training_model)   # tree plot
```
# predicting probabilities/class labels for test data
Now, the model will be evaluated on a test data. For this, we  apply the model to the test dataset and get the predicted values. It can be done by providing a dataset name with a model to `predict()` function. 
```{r}
test$ct_pred_prob<-predict(training_model,test)[,2]
test$ct_pred_class<-predict(training_model,test,type="class")
test
```

Check the accuracy of the model by comparing the the actual values (income) and the predicted values (ct_pred_class).
```{r}
table(test$income==test$ct_pred_class)    
```
accuracy = 5037 / (5037 + 963) = 0.8395

# k-fold Cross-validation 
```{r}
set.seed(1)   # set a random seed 
full_tree<-rpart(income~.,
                     data=training, 
                     method="class",
                     control=rpart.control(cp=0))

rpart.plot(full_tree)
```


```{r}
printcp(full_tree)   # xerror, xstd - cross validation results  
```

```{r}
plotcp(full_tree)    
```


```{r}
min_xerror<-full_tree$cptable[which.min(full_tree$cptable[,"xerror"]),]
min_xerror

# prune tree with minimum cp value
min_xerror_tree<-prune(full_tree, cp=min_xerror[1])
rpart.plot(min_xerror_tree)
```

Let's consider mim_xerror_tree as the best pruned tree, and get the prediction. 
```{r}
bp_tree<-min_xerror_tree
test$ct_bp_pred_prob<-predict(bp_tree,test)[,2]
test$ct_bp_pred_class=predict(bp_tree,test,type="class")

table(test$ct_bp_pred_class==test$income)  # error rate
table(test$ct_bp_pred_class,test$income, dnn=c("predicted","actual"))  # confusion table on test data
```
accuracy = 5137 / (5137 + 863) = 0.8562